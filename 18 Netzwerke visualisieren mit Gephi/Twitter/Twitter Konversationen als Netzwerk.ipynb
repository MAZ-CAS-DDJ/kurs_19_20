{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Konversationen zu einem Thema als Netzwerk untersuchen\n",
    "\n",
    "- Aus Twitter-Daten kann man besonders gut Netzwerke basteln.\n",
    "- Dabei können wir frei definieren,wann eigentlich ein Nutzer mit einem anderen verbunden ist. Die gebräuchlichsten Definitionen sind:\n",
    "    1. Nutzer A retweetet Nutzer B (RT plotti was für ein super tweet)\n",
    "    2. Nutzer A erwähnt Nutzer B (Ich geh das so die Straße lang und seh @plotti)\n",
    "    3. Nutzer A schreibt Nutzer B (@plotti was geht heute)\n",
    "    4. (Nutzer A folgt Nutzer B (Leider um die Struktur einer Konversationen nicht sooo hilfreich. Außerdem muss man über Twarc recht viele User sammeln um diese Information zu erhalten, es geht aber.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten Sammeln über Twarc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://github.com/DocNow/twarc\n",
    "- Twarc: A command line tool (and Python library) for archiving Twitter JSON\n",
    "- Sehr praktisch um Tweets zu einem Stichwort zu sammeln. \n",
    "- Man muss eine Twiter app beantragen :(\n",
    "- ```pip install twarc```\n",
    "- ```twarc configure```\n",
    "![Twarc](twarc.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten Sammeln "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```twarc search zürich > zürich.json```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import re\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd  \n",
    "import networkx as nx\n",
    "\n",
    "tweetfile = 'zürich.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Kanten erzeugen durch Retweets\n",
    "- Personen retweeten sich und deswegen erzeugen wir eine Kante zwischen ihnen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Export edges from Retweets\n",
    "\n",
    "fh = open(tweetfile, 'r')\n",
    "\n",
    "userdata = pd.DataFrame(columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count' ))\n",
    "edges = pd.DataFrame(columns=('Source','Target','Time', \"Strength\"))\n",
    "\n",
    "for line in fh:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "    except:\n",
    "        continue\n",
    "    if 'retweeted_status' not in tweet:\n",
    "        continue\n",
    "    \n",
    "    userdata = userdata.append(pd.DataFrame([[tweet['user']['id_str'],\n",
    "                                tweet['user']['screen_name'],\n",
    "                                tweet['user']['created_at'],\n",
    "                                tweet['user']['profile_image_url_https'],\n",
    "                                tweet['user']['followers_count'],\n",
    "                                tweet['user']['friends_count']]], columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count')), ignore_index=True)\n",
    "    userdata = userdata.append(pd.DataFrame([[tweet['retweeted_status']['user']['id_str'],\n",
    "                                tweet['retweeted_status']['user']['screen_name'],\n",
    "                                tweet['retweeted_status']['user']['created_at'],\n",
    "                                tweet['retweeted_status']['user']['profile_image_url_https'],\n",
    "                                tweet['retweeted_status']['user']['followers_count'],\n",
    "                                tweet['retweeted_status']['user']['friends_count']]], columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count')), ignore_index=True)                 \n",
    "    edges = edges.append(pd.DataFrame([[tweet['user']['id_str'],\n",
    "                                tweet['retweeted_status']['user']['id_str'],\n",
    "                                str(datetime.strptime(tweet['created_at'], '%a %b %d %H:%M:%S +0000 %Y')),1]]\n",
    "                                , columns=('Source','Target',\"Time\",'Strength')), ignore_index=True)           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Kanten erzeugen durch Mentions\n",
    "- Personen erwähnen sich und deshalb erzeugen wir eine Kante zwischen den Personen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fh = open(tweetfile, 'r')\n",
    "\n",
    "userdata = pd.DataFrame(columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count' ))\n",
    "edges = pd.DataFrame(columns=('Source','Target','Strength'))\n",
    "\n",
    "for line in fh:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "    except:\n",
    "        continue\n",
    "    if len(tweet['entities']['user_mentions']) == 0:\n",
    "        continue\n",
    "    \n",
    "    for mention in tweet['entities']['user_mentions']:\n",
    "        userdata = userdata.append(pd.DataFrame([[tweet['user']['id_str'],\n",
    "                                tweet['user']['screen_name'],\n",
    "                                tweet['user']['created_at'],\n",
    "                                tweet['user']['profile_image_url_https'],\n",
    "                                tweet['user']['followers_count'],\n",
    "                                tweet['user']['friends_count']]], columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count')), ignore_index=True)\n",
    "        if len(userdata[userdata['Id'].str.contains(mention['id_str'])]) == 0:\n",
    "            userdata = userdata.append(pd.DataFrame([[tweet['user']['id_str'],\n",
    "                                tweet['user']['screen_name'],\n",
    "                                np.nan,\n",
    "                                np.nan,\n",
    "                                np.nan,\n",
    "                                np.nan]], columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count')), ignore_index=True)\n",
    "        edges = edges.append(pd.DataFrame([[tweet['user']['id_str'],\n",
    "                                    mention['id_str'],\n",
    "                                    str(datetime.strptime(tweet['created_at'], '%a %b %d %H:%M:%S +0000 %Y'))]]\n",
    "                                    , columns=('Source','Target','Strength')), ignore_index=True)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Kanten erzeugen durch gemeinsame Kommunikation\n",
    "- Personen diskutieren miteinander und deshalb erzeugen wir eine Kante zwischen ihnen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fh = open(tweetfile, 'r')\n",
    "\n",
    "userdata = pd.DataFrame(columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count' ))\n",
    "edges = pd.DataFrame(columns=('Source','Target','Strength'))\n",
    "\n",
    "for line in fh:\n",
    "    try:\n",
    "        tweet = json.loads(line)\n",
    "    except:\n",
    "        continue\n",
    "    if tweet['in_reply_to_user_id_str'] is None:\n",
    "        continue\n",
    "\n",
    "    userdata = userdata.append(pd.DataFrame([[tweet['user']['id_str'],\n",
    "                                tweet['user']['screen_name'],\n",
    "                                tweet['user']['created_at'],\n",
    "                                tweet['user']['profile_image_url_https'],\n",
    "                                tweet['user']['followers_count'],\n",
    "                                tweet['user']['friends_count']]], columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count')), ignore_index=True)\n",
    "    if len(userdata[userdata['Id'].str.contains(tweet['in_reply_to_user_id_str'])]) == 0:\n",
    "            userdata = userdata.append(pd.DataFrame([[tweet['in_reply_to_user_id_str'],\n",
    "                                tweet['in_reply_to_screen_name'],\n",
    "                                np.nan,\n",
    "                                np.nan,\n",
    "                                np.nan,\n",
    "                                np.nan]], columns=('Id','Label','user_created_at','profile_image','followers_count','friends_count')), ignore_index=True)\n",
    "    edges = edges.append(pd.DataFrame([[tweet['user']['id_str'],\n",
    "                                tweet['in_reply_to_user_id_str'],\n",
    "                                str(datetime.strptime(tweet['created_at'], '%a %b %d %H:%M:%S +0000 %Y'))]]\n",
    "                                , columns=('Source','Target','Strength')), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nur jene Kanten behalten die eine gewisse Stärke haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strengthLevel = 3  # Network connection strength level: the number of times in total each of the tweeters responded to or mentioned the other.\n",
    "                   # If you have 1 as the level, then all tweeters who mentioned or replied to another at least once will be displayed. But if you have 5, only those who have mentioned or responded to a particular tweeter at least 5 times will be displayed, which means that only the strongest bonds are shown.\n",
    "\n",
    "edges2 = edges.groupby(['Source','Target'])['Strength'].count()\n",
    "edges2 = edges2.reset_index()\n",
    "edges2 = edges2[edges2['Strength'] >= strengthLevel]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(edges2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Daten als Gephi Netzwerk Exportieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def robust_decode(bs):\n",
    "    '''Takes a byte string as param and convert it into a unicode one.\n",
    "First tries UTF8, and fallback to Latin1 if it fails'''\n",
    "    cr = None\n",
    "    cr = bs.decode('ascii', 'ignore').encode('ascii')\n",
    "    return cr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "reload(sys)\n",
    "sys.setdefaultencoding('utf8')\n",
    "userdata = userdata.sort_values(['Id','followers_count'], ascending=[True, False])\n",
    "userdata = userdata.drop_duplicates(['Id'], keep='first') \n",
    "\n",
    "ids = edges2['Source'].append(edges2['Target']).to_frame()\n",
    "ids.columns = ['Id']\n",
    "ids = ids.drop_duplicates()\n",
    "\n",
    "nodes = pd.merge(ids, userdata, on='Id', how='left')\n",
    "nodes = nodes.dropna()\n",
    "nodes[\"Label\"] = nodes[\"Label\"].astype(str)\n",
    "nodes[\"Id\"] = nodes[\"Id\"].astype(str)\n",
    "\n",
    "\n",
    "G  = nx.DiGraph(name=\"zürich\")\n",
    "\n",
    "for i, row in nodes.iterrows():\n",
    "    G.add_node(robust_decode(row[\"Id\"]), label=robust_decode(row[\"Label\"]))\n",
    "\n",
    "for i, row in edges2.iterrows():\n",
    "    G.add_edge(robust_decode(row[\"Source\"]),robust_decode(row[\"Target\"]),weight=row[\"Strength\"])\n",
    "\n",
    "nx.write_gexf(G,\"Zürich.gexf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternativ als csv speichern für Kumu.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export nodes from the edges and add node attributes for both Sources and Targets.\n",
    "userdata = userdata.sort_values(['Id','followers_count'], ascending=[True, False])\n",
    "userdata = userdata.drop_duplicates(['Id'], keep='first') \n",
    "\n",
    "ids = edges2['Source'].append(edges2['Target']).to_frame()\n",
    "ids.columns = ['Id']\n",
    "ids = ids.drop_duplicates()\n",
    "\n",
    "nodes = pd.merge(ids, userdata, on='Id', how='left')\n",
    "\n",
    "# change column names for Kumu import (Run this when using Kumu)\n",
    "nodes.columns = ['Id', 'Label', 'Date', 'Image', 'followers_count', 'friends_count']\n",
    "edges2.columns = ['From','To','Strength']\n",
    "\n",
    "# Export nodes and edges to csv files\n",
    "nodes.to_csv('nodes.csv', encoding='utf-8', index=False)\n",
    "edges2.to_csv('edges.csv', encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
